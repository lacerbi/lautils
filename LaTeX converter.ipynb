{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fae3a8b5-db6c-460b-bac4-977e45f6752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def clean_latex_file(input_str):\n",
    "    r\"\"\"\n",
    "    Cleans a LaTeX file by removing comments, extracting content within \\begin{document} and \\end{document},\n",
    "    handling \\maketitle by replacing it with the title and authors in Markdown format,\n",
    "    and converting sections, figures, itemize/enumerate, equations, tables, etc. into a Markdown-friendly format.    \n",
    "    \"\"\"\n",
    "    content = None\n",
    "    \n",
    "    if isinstance(input_str, str) and '\\n' in input_str:\n",
    "        content = input_str\n",
    "\n",
    "    # Try to load from file if input is a filename\n",
    "    if not content:\n",
    "        if not input_str.endswith('.tex'):\n",
    "            raise ValueError(\"Input file must have a .tex extension.\")\n",
    "\n",
    "        base, _ = os.path.splitext(input_str)\n",
    "        output_path = f\"{base}.txt\"\n",
    "    \n",
    "        try:\n",
    "            with open(input_str, 'r', encoding='utf-8') as infile:\n",
    "                content = infile.read()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: The file {input_str} does not exist.\")\n",
    "            return\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            return\n",
    "    else:\n",
    "        output_path = \"output.txt\"\n",
    "\n",
    "    def preprocess_abstract(text):\n",
    "        text = re.sub(r'\\\\begin\\{abstract\\}', r'\\\\section*{Abstract}', text)\n",
    "        text = re.sub(r'\\\\end\\{abstract\\}', '', text)\n",
    "        return text\n",
    "\n",
    "    content = preprocess_abstract(content)\n",
    "\n",
    "    # Extract \\title and \\author from the entire content before extracting the document\n",
    "    def extract_title_authors(text):\n",
    "        title = \"\"\n",
    "        authors = \"\"\n",
    "        \n",
    "        # Pattern to match \\title{...} with nested braces\n",
    "        title_pattern = re.compile(r'\\\\title\\{')\n",
    "        title_match = title_pattern.search(text)\n",
    "        if title_match:\n",
    "            start = title_match.end()\n",
    "            brace_level = 1\n",
    "            i = start\n",
    "            while i < len(text) and brace_level > 0:\n",
    "                if text[i] == '{':\n",
    "                    brace_level += 1\n",
    "                elif text[i] == '}':\n",
    "                    brace_level -= 1\n",
    "                i += 1\n",
    "            if brace_level == 0:\n",
    "                title = text[start:i-1].strip()\n",
    "                # Remove the \\title{...} from text\n",
    "                text = text[:title_match.start()] + text[i:]\n",
    "            else:\n",
    "                print(\"Warning: Unbalanced braces in \\\\title command.\")\n",
    "                title = text[start:].strip()\n",
    "                text = text[:title_match.start()]\n",
    "        \n",
    "        # Pattern to match \\author{...} with nested braces\n",
    "        author_pattern = re.compile(r'\\\\author\\{')\n",
    "        author_match = author_pattern.search(text)\n",
    "        if author_match:\n",
    "            start = author_match.end()\n",
    "            brace_level = 1\n",
    "            i = start\n",
    "            while i < len(text) and brace_level > 0:\n",
    "                if text[i] == '{':\n",
    "                    brace_level += 1\n",
    "                elif text[i] == '}':\n",
    "                    brace_level -= 1\n",
    "                i += 1\n",
    "            if brace_level == 0:\n",
    "                authors = text[start:i-1].strip()\n",
    "                # Remove the \\author{...} from text\n",
    "                text = text[:author_match.start()] + text[i:]\n",
    "            else:\n",
    "                print(\"Warning: Unbalanced braces in \\\\author command.\")\n",
    "                authors = text[start:].strip()\n",
    "                text = text[:author_match.start()]\n",
    "        \n",
    "        return text, title, authors\n",
    "\n",
    "    content, title, authors = extract_title_authors(content)\n",
    "\n",
    "    # Extract content between \\begin{document} and \\end{document}, if present\n",
    "    doc_match = re.search(r'\\\\begin\\{document\\}(.*?)\\\\end\\{document\\}', content, flags=re.DOTALL)\n",
    "    if doc_match:\n",
    "        document_content = doc_match.group(1)\n",
    "    else:\n",
    "        # If \\begin{document} is not found, assume entire content is the document\n",
    "        document_content = content\n",
    "\n",
    "    # Remove comments (unescaped %)\n",
    "    document_content = re.sub(r'(?<!\\\\)%.*', '', document_content)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    document_content = re.sub(r'\\r\\n', '\\n', document_content)\n",
    "    document_content = re.sub(r'\\n{3,}', '\\n\\n', document_content)\n",
    "    document_content = document_content.replace('\\n\\n', '<<<PARA_BREAK>>>')\n",
    "    document_content = re.sub(r'\\n', ' ', document_content)\n",
    "    document_content = re.sub(r'\\s+', ' ', document_content).strip()\n",
    "    document_content = document_content.replace('<<<PARA_BREAK>>>', '\\n\\n')\n",
    "\n",
    "    def apply_inline_formats(text):\n",
    "        # \\emph{...}, \\textit{...} -> *...*\n",
    "        emph_pattern = re.compile(r'\\\\(?:emph|textit)\\{(.*?)\\}')\n",
    "        text = emph_pattern.sub(lambda m: \"*\" + m.group(1).strip() + \"*\", text)\n",
    "\n",
    "        # \\textbf{...} -> **...**\n",
    "        bold_pattern = re.compile(r'\\\\textbf\\{(.*?)\\}')\n",
    "        text = bold_pattern.sub(lambda m: \"**\" + m.group(1).strip() + \"**\", text)\n",
    "\n",
    "        # \\textsc{...} -> `...`\n",
    "        textsc_pattern = re.compile(r'\\\\textsc\\{(.*?)\\}')\n",
    "        text = textsc_pattern.sub(lambda m: \"`\" + m.group(1).strip() + \"`\", text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    def replace_maketitle(text, title, authors):\n",
    "        r\"\"\"\n",
    "        Replaces \\maketitle with Markdown-formatted title and authors.\n",
    "        \"\"\"\n",
    "        # Prepare Markdown replacement\n",
    "        replacement = \"\"\n",
    "        if title:\n",
    "            replacement += f\"# {apply_inline_formats(title)}\\n\\n\"\n",
    "        if authors:\n",
    "            # Split authors by \\and or commas\n",
    "            authors_clean = re.split(r'\\\\and|,', authors)\n",
    "            authors_clean = [a.strip() for a in authors_clean if a.strip()]\n",
    "            authors_md = ', '.join(authors_clean)\n",
    "            replacement += f\"**Authors:** {authors_md}\\n\\n\"\n",
    "\n",
    "        # Replace \\maketitle with the prepared Markdown using a lambda to avoid escape sequence issues\n",
    "        maketitle_pattern = re.compile(r'\\\\maketitle')\n",
    "        text = maketitle_pattern.sub(lambda m: replacement, text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    # Replace \\maketitle in the document content\n",
    "    document_content = replace_maketitle(document_content, title, authors)\n",
    "\n",
    "    def replace_figures(text):\n",
    "        figure_env = re.compile(r'\\\\begin\\{figure.*?\\}(.*?)\\\\end\\{figure.*?\\}', flags=re.DOTALL)\n",
    "\n",
    "        def figure_repl(m):\n",
    "            inner = m.group(1)\n",
    "            captions = []\n",
    "            labels = []\n",
    "\n",
    "            # Extract captions with nested brace handling\n",
    "            cap_start_pattern = re.compile(r'\\\\caption\\{')\n",
    "            pos = 0\n",
    "            while True:\n",
    "                cmatch = cap_start_pattern.search(inner, pos)\n",
    "                if not cmatch:\n",
    "                    break\n",
    "                start = cmatch.end()\n",
    "                brace_level = 1\n",
    "                i = start\n",
    "                while i < len(inner) and brace_level > 0:\n",
    "                    if inner[i] == '{':\n",
    "                        brace_level += 1\n",
    "                    elif inner[i] == '}':\n",
    "                        brace_level -= 1\n",
    "                    i += 1\n",
    "                if brace_level == 0:\n",
    "                    caption_text = inner[start:i-1].strip()\n",
    "                    # Remove any \\label{...} from caption_text\n",
    "                    caption_text = re.sub(r'\\\\label\\{[^}]+\\}', '', caption_text).strip()\n",
    "                    captions.append(caption_text)\n",
    "                    pos = i\n",
    "                else:\n",
    "                    # Unbalanced braces\n",
    "                    print(\"Warning: Unbalanced braces in figure caption.\")\n",
    "                    caption_text = inner[start:].strip()\n",
    "                    # Remove any \\label{...} from caption_text\n",
    "                    caption_text = re.sub(r'\\\\label\\{[^}]+\\}', '', caption_text).strip()\n",
    "                    captions.append(caption_text)\n",
    "                    break\n",
    "\n",
    "            full_caption = ' '.join(captions).strip()\n",
    "            full_caption = apply_inline_formats(full_caption)\n",
    "\n",
    "            # Extract labels\n",
    "            label_pattern = re.compile(r'\\\\label\\{([^}]+)\\}')\n",
    "            labels = label_pattern.findall(inner)\n",
    "\n",
    "            figure_markdown = \"\\n\\n**Figure:** \" + full_caption\n",
    "            for label in labels:\n",
    "                figure_markdown += f\" \\\\label{{{label}}}\"\n",
    "            figure_markdown += \"\\n\\n\"\n",
    "\n",
    "            return figure_markdown\n",
    "\n",
    "        return figure_env.sub(figure_repl, text)\n",
    "\n",
    "    document_content = replace_figures(document_content)\n",
    "\n",
    "    def has_nested_tabulars(text):\n",
    "        \"\"\"\n",
    "        Checks if there are nested tabular environments within the given text.\n",
    "        \n",
    "        Parameters:\n",
    "            text (str): The text to check for nested tabulars.\n",
    "        \n",
    "        Returns:\n",
    "            bool: True if nested tabulars are detected, False otherwise.\n",
    "        \"\"\"\n",
    "        open_tabulars = 0\n",
    "        pos = 0\n",
    "        while pos < len(text):\n",
    "            begin_match = re.search(r'\\\\begin\\{tabular\\}', text[pos:])\n",
    "            end_match = re.search(r'\\\\end\\{tabular\\}', text[pos:])\n",
    "            if begin_match:\n",
    "                begin_pos = pos + begin_match.start()\n",
    "            else:\n",
    "                begin_pos = None\n",
    "            if end_match:\n",
    "                end_pos = pos + end_match.start()\n",
    "            else:\n",
    "                end_pos = None\n",
    "            if begin_pos is not None and (end_pos is None or begin_pos < end_pos):\n",
    "                open_tabulars += 1\n",
    "                if open_tabulars > 1:\n",
    "                    return True\n",
    "                pos = begin_pos + len('\\\\begin{tabular}')\n",
    "            elif end_pos is not None:\n",
    "                open_tabulars -= 1\n",
    "                pos = end_pos + len('\\\\end{tabular}')\n",
    "            else:\n",
    "                break\n",
    "        return False\n",
    "\n",
    "    def convert_tabular_to_markdown(inner):\n",
    "        try:\n",
    "            # Remove scalebox if present\n",
    "            while True:\n",
    "                scalebox_match = re.search(r'\\\\scalebox\\{[^\\}]*\\}\\{', inner)\n",
    "                if not scalebox_match:\n",
    "                    break\n",
    "                inner = re.sub(r'\\\\scalebox\\{[^\\}]*\\}\\{(.*?)\\}', r'\\1', inner, flags=re.DOTALL)\n",
    "\n",
    "            # Check for nested tabulars\n",
    "            if has_nested_tabulars(inner):\n",
    "                # Nested tabulars detected\n",
    "                print(\"Warning: Nested tabular environments detected within a table.\")\n",
    "                return None  # Signal to handle verbatim copy\n",
    "\n",
    "            # Find all tabular environments\n",
    "            tabular_env = re.compile(r'\\\\begin\\{tabular\\}\\{.*?\\}(.*?)\\\\end\\{tabular\\}', flags=re.DOTALL)\n",
    "            tabulars = list(tabular_env.finditer(inner))\n",
    "\n",
    "            if not tabulars:\n",
    "                return \"\"\n",
    "\n",
    "            md_tables = []\n",
    "            for tabular in tabulars:\n",
    "                tabular_content = tabular.group(1)\n",
    "\n",
    "                # Remove booktabs lines\n",
    "                tabular_content = re.sub(r'\\\\toprule', '', tabular_content)\n",
    "                tabular_content = re.sub(r'\\\\midrule', '', tabular_content)\n",
    "                tabular_content = re.sub(r'\\\\bottomrule', '', tabular_content)\n",
    "                tabular_content = re.sub(r'\\\\cmidrule\\{[^\\}]*\\}', '', tabular_content)\n",
    "\n",
    "                rows = re.split(r'\\\\\\\\', tabular_content)\n",
    "                rows = [r.strip() for r in rows if r.strip()]\n",
    "\n",
    "                if not rows:\n",
    "                    continue  # Skip empty tabular\n",
    "\n",
    "                table_rows = []\n",
    "                for r in rows:\n",
    "                    r = re.sub(r'\\\\textcolor\\{[^\\}]*\\}\\{(.*?)\\}', r'\\1', r)\n",
    "                    r = re.sub(r'\\\\textbf\\{(.*?)\\}', r'**\\1**', r)\n",
    "                    r = re.sub(r'\\\\emph\\{(.*?)\\}', r'*\\1*', r)\n",
    "\n",
    "                    # Replace escaped chars\n",
    "                    r = r.replace(r'\\&', '&').replace(r'\\\\', '\\\\')\n",
    "\n",
    "                    cells = [c.strip() for c in r.split('&')]\n",
    "                    table_rows.append(cells)\n",
    "\n",
    "                num_cols = len(table_rows[0])\n",
    "\n",
    "                md_table = \"\\n\\n| \" + \" | \".join(table_rows[0]) + \" |\\n\"\n",
    "                md_table += \"| \" + \" | \".join([\"---\"] * num_cols) + \" |\\n\"\n",
    "                for row in table_rows[1:]:\n",
    "                    if len(row) < num_cols:\n",
    "                        row += [\"\"] * (num_cols - len(row))\n",
    "                    elif len(row) > num_cols:\n",
    "                        row = row[:num_cols]\n",
    "                    md_table += \"| \" + \" | \".join(row) + \" |\\n\"\n",
    "                md_table += \"\\n\\n\"\n",
    "\n",
    "                md_tables.append(md_table)\n",
    "\n",
    "            # Combine all markdown tables\n",
    "            return ''.join(md_tables)\n",
    "        except Exception as e:\n",
    "            print(f\"Error during tabular conversion: {e}\")\n",
    "            return \"\"\n",
    "\n",
    "    def remove_captions_and_labels(tex):\n",
    "        r\"\"\"\n",
    "        Remove all \\caption{...} commands (with possible nested braces)\n",
    "        and all \\label\\{...\\} commands from the given LaTeX code.\n",
    "        \"\"\"\n",
    "        # Remove captions with nested braces\n",
    "        out = \"\"\n",
    "        start_idx = 0\n",
    "        caption_pattern = re.compile(r'\\\\caption\\{')\n",
    "        while True:\n",
    "            cmatch = caption_pattern.search(tex, start_idx)\n",
    "            if not cmatch:\n",
    "                # no more captions\n",
    "                break\n",
    "            out += tex[start_idx:cmatch.start()]\n",
    "            # find matching braces\n",
    "            pos = cmatch.end()\n",
    "            brace_level = 1\n",
    "            while pos < len(tex) and brace_level > 0:\n",
    "                if tex[pos] == '{':\n",
    "                    brace_level += 1\n",
    "                elif tex[pos] == '}':\n",
    "                    brace_level -= 1\n",
    "                pos += 1\n",
    "            # skip this entire caption block\n",
    "            start_idx = pos\n",
    "        out += tex[start_idx:]\n",
    "\n",
    "        # Now remove labels\n",
    "        out = re.sub(r'\\\\label\\{[^}]+\\}', '', out)\n",
    "        return out\n",
    "\n",
    "    def replace_tables(text):\n",
    "        table_env = re.compile(r'(\\\\begin\\{table.*?\\}.*?\\\\end\\{table.*?\\})', flags=re.DOTALL)\n",
    "\n",
    "        def table_repl(m):\n",
    "            entire_table = m.group(1)\n",
    "\n",
    "            # Extract captions with nested brace handling\n",
    "            captions = []\n",
    "            pos = 0\n",
    "            cap_start_pattern = re.compile(r'\\\\caption\\{')\n",
    "            while True:\n",
    "                cmatch = cap_start_pattern.search(entire_table, pos)\n",
    "                if not cmatch:\n",
    "                    break\n",
    "                start = cmatch.end()\n",
    "                brace_level = 1\n",
    "                i = start\n",
    "                while i < len(entire_table) and brace_level > 0:\n",
    "                    if entire_table[i] == '{':\n",
    "                        brace_level += 1\n",
    "                    elif entire_table[i] == '}':\n",
    "                        brace_level -= 1\n",
    "                    i += 1\n",
    "                if brace_level == 0:\n",
    "                    caption_text = entire_table[start:i-1].strip()\n",
    "                    # Remove any \\label{...} from caption_text\n",
    "                    caption_text = re.sub(r'\\\\label\\{[^}]+\\}', '', caption_text).strip()\n",
    "                    captions.append(caption_text)\n",
    "                    pos = i\n",
    "                else:\n",
    "                    print(\"Warning: Unbalanced braces in table caption.\")\n",
    "                    caption_text = entire_table[start:].strip()\n",
    "                    # Remove any \\label{...} from caption_text\n",
    "                    caption_text = re.sub(r'\\\\label\\{[^}]+\\}', '', caption_text).strip()\n",
    "                    captions.append(caption_text)\n",
    "                    break\n",
    "\n",
    "            full_caption = ' '.join(captions).strip()\n",
    "            full_caption = apply_inline_formats(full_caption)\n",
    "\n",
    "            # Extract labels\n",
    "            label_pattern = re.compile(r'\\\\label\\{([^}]+)\\}')\n",
    "            labels = label_pattern.findall(entire_table)\n",
    "\n",
    "            # Convert tabular to markdown\n",
    "            markdown_table = convert_tabular_to_markdown(entire_table)\n",
    "\n",
    "            if markdown_table is None:\n",
    "                # Nested tabulars detected\n",
    "                print(\"Warning: Nested tabular environments detected. Retaining tabular content as LaTeX code.\")\n",
    "                \n",
    "                # Extract all tabular environments\n",
    "                tabulars = re.findall(r'\\\\begin\\{tabular\\}.*?\\\\end\\{tabular\\}', entire_table, flags=re.DOTALL)\n",
    "                tabular_content = '\\n'.join(tabulars)\n",
    "\n",
    "                # Prepare Markdown with caption and label, and include tabular as code block\n",
    "                labels_str = ' '.join([f\"\\\\label{{{label}}}\" for label in labels])\n",
    "                table_markdown = f\"\\n\\n**Table:** {full_caption} {labels_str}\\n\\n```latex\\n{tabular_content}\\n```\\n\\n\"\n",
    "\n",
    "                return table_markdown\n",
    "\n",
    "            if not markdown_table:\n",
    "                # Conversion failed or no tabulars found\n",
    "                print(\"Warning: Table conversion failed or no tabular environments found. Retaining original LaTeX table without captions and labels.\")\n",
    "                cleaned_table = remove_captions_and_labels(entire_table)\n",
    "                # Append labels to the caption\n",
    "                labels_str = ' '.join([f\"\\\\label{{{label}}}\" for label in labels])\n",
    "                return f\"\\n\\n**Table:** {full_caption} {labels_str}\\n\\n```latex\\n{cleaned_table}\\n```\\n\\n\"\n",
    "\n",
    "            # Conversion succeeded\n",
    "            # Append labels to the caption\n",
    "            labels_str = ' '.join([f\"\\\\label{{{label}}}\" for label in labels])\n",
    "            table_markdown = f\"\\n\\n**Table:** {full_caption} {labels_str}\\n\\n{markdown_table}\\n\"\n",
    "\n",
    "            return table_markdown\n",
    "\n",
    "        return table_env.sub(table_repl, text)\n",
    "\n",
    "    document_content = replace_tables(document_content)\n",
    "\n",
    "    def replace_equations(text):\n",
    "        eq_env = re.compile(r'\\\\begin\\{equation\\}(.*?)\\\\end\\{equation\\}', flags=re.DOTALL)\n",
    "\n",
    "        def eq_repl(m):\n",
    "            eq_text = m.group(1).strip()\n",
    "            eq_text = re.sub(r'(\\\\label\\{[^}]+\\})\\s*', r'\\1\\n', eq_text)\n",
    "            return \"\\n\\n$$\\n\" + eq_text + \"\\n$$\\n\\n\"\n",
    "\n",
    "        return eq_env.sub(eq_repl, text)\n",
    "\n",
    "    document_content = replace_equations(document_content)\n",
    "\n",
    "    def replace_headings(text):\n",
    "        sec_pattern = re.compile(\n",
    "            r'\\\\(section|subsection|subsubsection|paragraph|runningtitle)\\*?\\{(.*?)\\}'\n",
    "            r'(?:\\s*\\\\label\\{([^}]+)\\})?', flags=re.DOTALL\n",
    "        )\n",
    "\n",
    "        def sec_repl(m):\n",
    "            level_map = {\n",
    "                \"section\": 1,\n",
    "                \"subsection\": 2,\n",
    "                \"subsubsection\": 3,\n",
    "                \"paragraph\": 4,\n",
    "                \"runningtitle\": 1\n",
    "            }\n",
    "            level = level_map.get(m.group(1), 2)\n",
    "            title = m.group(2).strip()\n",
    "            label = m.group(3)\n",
    "\n",
    "            markdown = \"\\n\\n\" + \"#\"*level + \" \" + title\n",
    "            if label:\n",
    "                markdown += \"\\n\\\\label{\" + label + \"}\"\n",
    "            markdown += \"\\n\\n\"\n",
    "\n",
    "            return markdown\n",
    "\n",
    "        return sec_pattern.sub(sec_repl, text)\n",
    "\n",
    "    document_content = replace_headings(document_content)\n",
    "\n",
    "    def replace_lists(text):\n",
    "        enum_env = re.compile(r'\\\\begin\\{enumerate\\}(\\[[^\\]]*\\])?(.*?)\\\\end\\{enumerate\\}', flags=re.DOTALL)\n",
    "        def enum_repl(m):\n",
    "            inner = m.group(2)\n",
    "            items = re.split(r'\\\\item', inner)\n",
    "            items = [i.strip() for i in items if i.strip()]\n",
    "            result = \"\\n\\n\"\n",
    "            for idx, it in enumerate(items, start=1):\n",
    "                it = apply_inline_formats(it)\n",
    "                result += f\"{idx}. {it}\\n\"\n",
    "            result += \"\\n\"\n",
    "            return result\n",
    "\n",
    "        text = enum_env.sub(enum_repl, text)\n",
    "\n",
    "        item_env = re.compile(r'\\\\begin\\{itemize\\}(\\[[^\\]]*\\])?(.*?)\\\\end\\{itemize\\}', flags=re.DOTALL)\n",
    "        def item_repl(m):\n",
    "            inner = m.group(2)\n",
    "            items = re.split(r'\\\\item', inner)\n",
    "            items = [i.strip() for i in items if i.strip()]\n",
    "            result = \"\\n\\n\"\n",
    "            for it in items:\n",
    "                it = apply_inline_formats(it)\n",
    "                result += f\"- {it}\\n\"\n",
    "            result += \"\\n\"\n",
    "            return result\n",
    "\n",
    "        text = item_env.sub(item_repl, text)\n",
    "        text = re.sub(r'\\\\item\\s+', '\\n- ', text)\n",
    "\n",
    "        return text\n",
    "\n",
    "    document_content = replace_lists(document_content)\n",
    "\n",
    "    def replace_inline_formats_func(text):\n",
    "        return apply_inline_formats(text)\n",
    "\n",
    "    document_content = replace_inline_formats_func(document_content)\n",
    "\n",
    "    def remove_latex_command(text, command):\n",
    "        \"\"\"\n",
    "        Removes all instances of a LaTeX command with its argument, handling nested braces.\n",
    "        \n",
    "        Parameters:\n",
    "            text (str): The input text.\n",
    "            command (str): The LaTeX command to remove (e.g., 'ignore').\n",
    "        \n",
    "        Returns:\n",
    "            str: The text with the specified command removed.\n",
    "        \"\"\"\n",
    "        pattern = re.compile(r'\\\\' + re.escape(command) + r'\\{')\n",
    "        result = []\n",
    "        pos = 0\n",
    "        while True:\n",
    "            cmatch = pattern.search(text, pos)\n",
    "            if not cmatch:\n",
    "                result.append(text[pos:])\n",
    "                break\n",
    "            start = cmatch.start()\n",
    "            result.append(text[pos:start])\n",
    "            brace_level = 1\n",
    "            i = cmatch.end()\n",
    "            while i < len(text) and brace_level > 0:\n",
    "                if text[i] == '{':\n",
    "                    brace_level += 1\n",
    "                elif text[i] == '}':\n",
    "                    brace_level -= 1\n",
    "                i += 1\n",
    "            pos = i  # Move past the closing brace\n",
    "        return ''.join(result)\n",
    "\n",
    "    def remove_leftover_commands(text):\n",
    "        r\"\"\"\n",
    "        Remove all specified LaTeX commands from the text, handling nested braces.\n",
    "        \"\"\"\n",
    "        commands_to_remove = ['vspace', 'hspace', 'bigskip', 'smallskip', 'medskip', 'ignore', 'bibliographystyle']\n",
    "        commands_to_replace_newline = ['newpage', 'pagebreak', 'linebreak', 'clearpage', 'cleardoublepage']\n",
    "\n",
    "        for cmd in commands_to_remove:\n",
    "            text = remove_latex_command(text, cmd)\n",
    "\n",
    "        # Remove commands without arguments\n",
    "        remove_pattern = re.compile(\n",
    "            r'\\\\(?:' + '|'.join(commands_to_remove) + r')\\s*'\n",
    "        )\n",
    "        text = remove_pattern.sub('', text)\n",
    "\n",
    "        # Replace newline commands with two newlines\n",
    "        replace_newline_pattern = re.compile(\n",
    "            r'\\\\(?:' + '|'.join(commands_to_replace_newline) + r')\\s*'\n",
    "        )\n",
    "        text = replace_newline_pattern.sub('\\n\\n', text)\n",
    "\n",
    "        # Clean up extra newlines\n",
    "        text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "        return text\n",
    "\n",
    "    document_content = remove_leftover_commands(document_content)\n",
    "\n",
    "    def remove_formatting_cmds(text):\n",
    "        formatting_cmds = re.compile(\n",
    "            r'\\\\(vspace|hspace|bigskip|newpage|smallskip|medskip|pagebreak|linebreak|clearpage|cleardoublepage)'\n",
    "            r'(\\[[^\\]]*\\])?(\\{[^}]*\\})?'\n",
    "        )\n",
    "        return formatting_cmds.sub(' ', text)\n",
    "\n",
    "    document_content = remove_formatting_cmds(document_content)\n",
    "\n",
    "    document_content = re.sub(r'\\n\\n\\s+', '\\n\\n', document_content)\n",
    "\n",
    "    def final_cleanup(text):\n",
    "        text = re.sub(r' {2,}', ' ', text)\n",
    "        text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
    "        return text.strip() + \"\\n\"\n",
    "\n",
    "    document_content = final_cleanup(document_content)\n",
    "\n",
    "    try:\n",
    "        with open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "            outfile.write(document_content)\n",
    "        print(f\"Cleaned file has been written to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while writing the output file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "bc591044-5ae6-445d-ac32-205785145e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tarfile\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "def get_arxiv_tex(identifier):\n",
    "    \"\"\"\n",
    "    Download and extract arXiv source files, returning the main tex content.\n",
    "    \n",
    "    Args:\n",
    "        identifier (str): Either full arXiv URL or just the paper number (e.g. '2412.06264')\n",
    "        \n",
    "    Returns:\n",
    "        str: Content of the main tex file\n",
    "        \n",
    "    Raises:\n",
    "        ValueError: If the identifier is invalid or source files cannot be accessed\n",
    "        RuntimeError: If no main tex file is found\n",
    "    \"\"\"\n",
    "    # Extract paper number from URL if needed\n",
    "    if identifier.startswith('http'):\n",
    "        match = re.search(r'arxiv.org/(?:abs|pdf)/(\\d+\\.\\d+)', identifier)\n",
    "        if not match:\n",
    "            raise ValueError(\"Invalid arXiv URL format\")\n",
    "        paper_number = match.group(1)\n",
    "    else:\n",
    "        # Verify the paper number format\n",
    "        if not re.match(r'^\\d+\\.\\d+$', identifier):\n",
    "            raise ValueError(\"Invalid arXiv identifier format\")\n",
    "        paper_number = identifier\n",
    "    \n",
    "    # Create source URL\n",
    "    source_url = f'https://arxiv.org/src/{paper_number}'\n",
    "    \n",
    "    # Download the source files\n",
    "    response = requests.get(source_url)\n",
    "    if response.status_code != 200:\n",
    "        raise ValueError(f\"Failed to download source files (Status code: {response.status_code})\")\n",
    "    \n",
    "    # Create a temporary directory for extraction\n",
    "    with tempfile.TemporaryDirectory() as temp_dir:\n",
    "        # Save the downloaded tar file\n",
    "        tar_path = Path(temp_dir) / 'source.tar.gz'\n",
    "        with open(tar_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        # Extract the tar file using the new filter parameter\n",
    "        with tarfile.open(tar_path, 'r:gz') as tar:\n",
    "            tar.extractall(path=temp_dir, filter='data')\n",
    "        \n",
    "        # Look for main tex file\n",
    "        tex_files = list(Path(temp_dir).rglob('*.tex'))\n",
    "        if not tex_files:\n",
    "            raise RuntimeError(\"No tex files found in the source\")\n",
    "        \n",
    "        # Common main file names (all lowercase for comparison)\n",
    "        main_candidates = [\n",
    "            'main.tex',\n",
    "            'paper.tex',\n",
    "            'article.tex',\n",
    "            'manuscript.tex',\n",
    "            'submission.tex',\n",
    "            'arxiv.tex',\n",
    "            'document.tex',\n",
    "            'draft.tex',\n",
    "            'preprint.tex',\n",
    "            'source.tex',\n",
    "            'neurips.tex',\n",
    "            'icml.tex',\n",
    "            'iclr.tex',\n",
    "            'aaai.tex',\n",
    "            'ijcai.tex',\n",
    "            f'{paper_number}.tex'\n",
    "        ]\n",
    "        \n",
    "        main_file = None\n",
    "        \n",
    "        # First try common file names (case-insensitive)\n",
    "        for candidate in main_candidates:\n",
    "            for tex_file in tex_files:\n",
    "                if tex_file.name.lower() == candidate:\n",
    "                    main_file = tex_file\n",
    "                    break\n",
    "            if main_file:\n",
    "                break\n",
    "                \n",
    "        # If no common names found, try the directory name (case-insensitive)\n",
    "        if not main_file:\n",
    "            for tex_file in tex_files:\n",
    "                if tex_file.parent.name.lower() + '.tex' == tex_file.name.lower():\n",
    "                    main_file = tex_file\n",
    "                    break\n",
    "        \n",
    "        # If still no match, look for file with \\documentclass\n",
    "        if not main_file:\n",
    "            for tex_file in tex_files:\n",
    "                with open(tex_file, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    if r'\\documentclass' in content:\n",
    "                        main_file = tex_file\n",
    "                        break\n",
    "        \n",
    "        # If still no main file found, use the first tex file\n",
    "        if not main_file and tex_files:\n",
    "            main_file = tex_files[0]\n",
    "        \n",
    "        if not main_file:\n",
    "            raise RuntimeError(\"Could not identify main tex file\")\n",
    "        \n",
    "        # Read and return the content\n",
    "        with open(main_file, 'r', encoding='utf-8') as f:\n",
    "            return f.read()\n",
    "            \n",
    "# Example usage:\n",
    "# tex_content = get_arxiv_tex('2412.06264')\n",
    "# tex_content = get_arxiv_tex('https://arxiv.org/abs/2412.06264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b097ced7-e82e-4d2b-94c5-f4d8b1452599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Nested tabular environments detected within a table.\n",
      "Warning: Nested tabular environments detected. Retaining tabular content as LaTeX code.\n",
      "Cleaned file has been written to: output.txt\n"
     ]
    }
   ],
   "source": [
    "#input_file = './maintext.tex'  # Replace with your .tex file path\n",
    "input_file = get_arxiv_tex('2412.06264')\n",
    "clean_latex_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c555f313-d95e-431c-ad28-4dd8da0e6d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
